apiVersion: batch/v1
kind: Job
metadata:
  name: gxa-solrcloud-bulk-analytics-populator
  namespace: jenkins-gene-expression
spec:
  template:
    spec:
      volumes:
        - name: gxa-bulk-analytics-jsonl-vol
          persistentVolumeClaim:
            claimName: gxa-bulk-analytics-jsonl-rwo
        - name: scratch-bulk-analytics-vol
          ephemeral:
            volumeClaimTemplate:
              spec:
                accessModes: [ "ReadWriteOnce" ]
                storageClassName: "premium-rwo"
                resources:
                  requests:
                    storage: 150Gi
      containers:
        - name: gxa-solrcloud-populator
          image: quay.io/ebigxa/gxa-atlas-web-bulk-postgres-solrcloud-populator:latest
          env:
            - name: SOLR_HOST
              value: "gxa-solrcloud-0.gxa-solrcloud-headless.jenkins-gene-expression.svc.cluster.local:8983"
            - name: SOLR_HOSTS
              value: "gxa-solrcloud-0.gxa-solrcloud-headless.jenkins-gene-expression.svc.cluster.local:8983 gxa-solrcloud-1.gxa-solrcloud-headless.jenkins-gene-expression.svc.cluster.local:8983 gxa-solrcloud-2.gxa-solrcloud-headless.jenkins-gene-expression.svc.cluster.local:8983 gxa-solrcloud-3.gxa-solrcloud-headless.jenkins-gene-expression.svc.cluster.local:8983"
            - name: SOLR_NUM_SHARDS
              value: "4"
            - name: NUM_DOCS_PER_BATCH
              value: "10000"
            - name: SOLR_COMMIT_DOCS
              value: "500000"
            - name: SOLR_COLLECTION
              value: "bulk-analytics"
            - name: SCHEMA_VERSION
              value: "1"
            # Consider moving this to an export line in the script (?)
            - name: SOLR_PROCESSORS
              value: "dedupe"
          resources:
            requests:
              cpu: 0.1
              memory: 128Mi
            limits:
              cpu: 0.25
              memory: 1Gi
          args:
            - |
              cd /root/solr-bulk/bin
              ./create-bulk-analytics-collection.sh
              ./create-bulk-analytics-schema.sh

              # We go back to index-bioentities/bin because the solr-jsonl-chunk-loader.sh script isnâ€™t in the solr-bulk repository
              cd /atlas-data/scratch
              for FILE in `ls /atlas-data/bulk-analytics-jsonl/*.jsonl`
              do
                INPUT_JSONL=${FILE} /root/index-bioentities/bin/solr-jsonl-chunk-loader.sh >> /dev/stdout 2>&1
              done
          volumeMounts:
            - mountPath: "/atlas-data/bulk-analytics-jsonl"
              name: gxa-bulk-analytics-jsonl-vol
            - mountPath: "/atlas-data/scratch"
              name: scratch-bulk-analytics-vol
      restartPolicy: Never
